{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name=\"Case Study 2: Email Analytics\"\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(app_name)\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set(\"spark.driver.host\", \"localhost\")\n",
    "        .set('spark.executor.memory', '4G')\n",
    "        .set('spark.driver.memory', '8G')\n",
    "        .set('spark.driver.maxResultSize', '10G'))\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local-1572747584512'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "LOGGER.info(\"pyspark script logger initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def set_pandas_options() -> None:\n",
    "    pd.options.display.max_columns = 100\n",
    "    pd.options.display.max_rows = 100\n",
    "    pd.options.display.max_colwidth = 120\n",
    "    pd.options.display.width = 140\n",
    "    \n",
    "set_pandas_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load data into Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdfs_filepath(file_name, on_cloud=False):\n",
    "    # path to folder containing this code\n",
    "    prefix = '/data/spark/8_cs2_dataset/'\n",
    "    if on_cloud:\n",
    "        bucket  = os.environ['BUCKET']\n",
    "        file_path = bucket + prefix + file_name\n",
    "    else:\n",
    "        file_path = '/Users/val' + prefix + file_name\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = get_hdfs_filepath('*/*/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/val/data/spark/8_cs2_dataset/*/*/*\n"
     ]
    }
   ],
   "source": [
    "print(LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_txt_df=sc.wholeTextFiles(LOG).filter(lambda line: line != '').toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import dateutil.parser\n",
    "import pytz\n",
    "\n",
    "def to_utc_timestamp(string):\n",
    "    zone_idx = string.find('-') if string.find('-') >= 0 else string.find('+')\n",
    "    zone_abbr = string[string.find('(')-1:string.find(')')] # not used\n",
    "    timezone_str = string[zone_idx:string.find('(')-1]\n",
    "    date_time_str = string[:zone_idx-1]\n",
    "    date_time_obj = dt.datetime.strptime(date_time_str, '%d %b %Y %H:%M:%S')\n",
    "    dt2 = dateutil.parser.parse(str(date_time_obj)+timezone_str)\n",
    "    return dt2.astimezone(pytz.timezone(\"UTC\"))\n",
    "\n",
    "converted = to_utc_timestamp('12 Dec 2015 18:25:11 -0700 (PDT)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 12, 13, 1, 25, 11, tzinfo=<UTC>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "df = log_txt_df\n",
    "#df.line =  df.line.cast(StringType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(df._2.alias('line') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Message-ID: &lt;9838605.1075853079790.JavaMail.evans@thyme&gt;\\r\\nDate: Thu, 23 Aug 2001 09:24:44 -0700 (PDT)\\r\\nFrom: lyn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      line\n",
       "0  Message-ID: <9838605.1075853079790.JavaMail.evans@thyme>\\r\\nDate: Thu, 23 Aug 2001 09:24:44 -0700 (PDT)\\r\\nFrom: lyn..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>UTC_timestamp</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Cc</th>\n",
       "      <th>Mime_Version</th>\n",
       "      <th>Content_Type</th>\n",
       "      <th>Content_Transfer_Encoding</th>\n",
       "      <th>X_From</th>\n",
       "      <th>X_To</th>\n",
       "      <th>X_cc</th>\n",
       "      <th>X_bcc</th>\n",
       "      <th>X_Folder</th>\n",
       "      <th>X_Origin</th>\n",
       "      <th>X_FileName</th>\n",
       "      <th>FYI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>23 Aug 2001 09:24:44 -0700 (PDT)</td>\n",
       "      <td>2001-08-23 12:24:44</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>shelley.corman@enron.com</td>\n",
       "      <td>FW: PAA</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=LBLAIR&gt;</td>\n",
       "      <td>Corman, Shelley &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Scorman&gt;</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Outbox</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Shelley, Larry Berger has put together the 4 PAA's based on these employeef efforts on the testing of the new Flowin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>11 Jun 2001 14:06:00 -0700 (PDT)</td>\n",
       "      <td>2001-06-11 17:06:00</td>\n",
       "      <td>shelley.corman@enron.com</td>\n",
       "      <td>steve.hotte@enron.com, steven.january@enron.com, lynn.blair@enron.com, mike.bryant@enron.com</td>\n",
       "      <td>Follow-up on Weekend</td>\n",
       "      <td>gina.taylor@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Shelley Corman &lt;Shelley Corman/ENRON@enronXgate&gt;</td>\n",
       "      <td>Steve Hotte &lt;Steve Hotte/ENRON@enronXgate&gt;, Steven January &lt;Steven January/ET&amp;S/Enron@ENRON&gt;, Lynn Blair &lt;Lynn Blair...</td>\n",
       "      <td>Gina Taylor &lt;Gina Taylor/ENRON@enronXgate&gt;</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Tropical Storm Allison</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>I propose that we put in place the following plan to follow-up with employees:1. Thank you from Stan to all employee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>26 Sep 2001 06:11:50 -0700 (PDT)</td>\n",
       "      <td>2001-09-26 09:11:50</td>\n",
       "      <td>gary.kenagy@enron.com</td>\n",
       "      <td>ricki.winters@enron.com, console.security@enron.com</td>\n",
       "      <td>RE: Security Access</td>\n",
       "      <td>lynn.blair@enron.com, rick.dietz@enron.com, sheila.nacey@enron.com, bradley.holmes@enron.com, steven.january@enron.c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Kenagy, Gary &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=GKENAGY&gt;</td>\n",
       "      <td>Winters, Ricki &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rwinter&gt;, Security Console, &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Notesad...</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;, Dietz, Rick &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rdietz&gt;, Nacey, S...</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Security, Everyone on the attached list will require after hours access to the common areas on EB39 and EB42. Please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>20 Sep 2001 14:41:21 -0700 (PDT)</td>\n",
       "      <td>2001-09-20 17:41:21</td>\n",
       "      <td>audrey.robertson@enron.com</td>\n",
       "      <td>dennis.alters@enron.com, ben.asante@enron.com, ramona.betancourt@enron.com, lynn.blair@enron.com, bob.burleson@enron...</td>\n",
       "      <td>FW: New Location for Steve Harris' Staff Meeting</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Robertson, Audrey &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=AROBERT&gt;</td>\n",
       "      <td>Alters, Dennis &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dalters&gt;, Asante, Ben &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Basante&gt;, Bet...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Please be informed, Steve Harris and the TW Commercial Group will temporarily relocated to the 13th floor effective ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>24 Sep 2001 14:09:13 -0700 (PDT)</td>\n",
       "      <td>2001-09-24 17:09:13</td>\n",
       "      <td>donna.scott@enron.com</td>\n",
       "      <td>darrell.schoolcraft@enron.com, terry.kowalke@enron.com, laura.giambrone@enron.com, tracy.minter@enron.com, amy.mulli...</td>\n",
       "      <td>TW Move Information</td>\n",
       "      <td>lynn.blair@enron.com, steven.january@enron.com, john.buchanan@enron.com, donna.scott@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Scott, Donna &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=DSCOTT1&gt;</td>\n",
       "      <td>Schoolcraft, Darrell &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dschool&gt;, Kowalke, Terry &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tkow...</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;, January, Steven &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Sjanuary&gt;, Bu...</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>The following individuals are scheduled to move September 27th (Thursday).  Please have your boxes and equipment lab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID                              Date       UTC_timestamp                        From  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme  23 Aug 2001 09:24:44 -0700 (PDT) 2001-08-23 12:24:44        lynn.blair@enron.com   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme  11 Jun 2001 14:06:00 -0700 (PDT) 2001-06-11 17:06:00    shelley.corman@enron.com   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme  26 Sep 2001 06:11:50 -0700 (PDT) 2001-09-26 09:11:50       gary.kenagy@enron.com   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme  20 Sep 2001 14:41:21 -0700 (PDT) 2001-09-20 17:41:21  audrey.robertson@enron.com   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme  24 Sep 2001 14:09:13 -0700 (PDT) 2001-09-24 17:09:13       donna.scott@enron.com   \n",
       "\n",
       "                                                                                                                        To  \\\n",
       "0                                                                                                 shelley.corman@enron.com   \n",
       "1                             steve.hotte@enron.com, steven.january@enron.com, lynn.blair@enron.com, mike.bryant@enron.com   \n",
       "2                                                                      ricki.winters@enron.com, console.security@enron.com   \n",
       "3  dennis.alters@enron.com, ben.asante@enron.com, ramona.betancourt@enron.com, lynn.blair@enron.com, bob.burleson@enron...   \n",
       "4  darrell.schoolcraft@enron.com, terry.kowalke@enron.com, laura.giambrone@enron.com, tracy.minter@enron.com, amy.mulli...   \n",
       "\n",
       "                                            Subject  \\\n",
       "0                                           FW: PAA   \n",
       "1                              Follow-up on Weekend   \n",
       "2                               RE: Security Access   \n",
       "3  FW: New Location for Steve Harris' Staff Meeting   \n",
       "4                               TW Move Information   \n",
       "\n",
       "                                                                                                                        Cc Mime_Version  \\\n",
       "0                                                                                                     lynn.blair@enron.com          1.0   \n",
       "1                                                                                                    gina.taylor@enron.com          1.0   \n",
       "2  lynn.blair@enron.com, rick.dietz@enron.com, sheila.nacey@enron.com, bradley.holmes@enron.com, steven.january@enron.c...          1.0   \n",
       "3                                                                                                                                   1.0   \n",
       "4                           lynn.blair@enron.com, steven.january@enron.com, john.buchanan@enron.com, donna.scott@enron.com          1.0   \n",
       "\n",
       "                   Content_Type Content_Transfer_Encoding                                                       X_From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit         Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=LBLAIR>   \n",
       "1  text/plain; charset=us-ascii                      7bit             Shelley Corman <Shelley Corman/ENRON@enronXgate>   \n",
       "2  text/plain; charset=us-ascii                      7bit       Kenagy, Gary </O=ENRON/OU=NA/CN=RECIPIENTS/CN=GKENAGY>   \n",
       "3  text/plain; charset=us-ascii                      7bit  Robertson, Audrey </O=ENRON/OU=NA/CN=RECIPIENTS/CN=AROBERT>   \n",
       "4  text/plain; charset=us-ascii                      7bit       Scott, Donna </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DSCOTT1>   \n",
       "\n",
       "                                                                                                                      X_To  \\\n",
       "0                                                                Corman, Shelley </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Scorman>   \n",
       "1  Steve Hotte <Steve Hotte/ENRON@enronXgate>, Steven January <Steven January/ET&S/Enron@ENRON>, Lynn Blair <Lynn Blair...   \n",
       "2  Winters, Ricki </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rwinter>, Security Console, </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Notesad...   \n",
       "3  Alters, Dennis </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dalters>, Asante, Ben </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Basante>, Bet...   \n",
       "4  Schoolcraft, Darrell </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dschool>, Kowalke, Terry </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tkow...   \n",
       "\n",
       "                                                                                                                      X_cc X_bcc  \\\n",
       "0                                                                     Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>         \n",
       "1                                                                               Gina Taylor <Gina Taylor/ENRON@enronXgate>         \n",
       "2  Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>, Dietz, Rick </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rdietz>, Nacey, S...         \n",
       "3                                                                                                                                  \n",
       "4  Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>, January, Steven </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Sjanuary>, Bu...         \n",
       "\n",
       "                                                      X_Folder X_Origin                X_FileName  \\\n",
       "0                  \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Outbox  Blair-L  LBLAIR (Non-Privileged).   \n",
       "1  \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Tropical Storm Allison  Blair-L  LBLAIR (Non-Privileged).   \n",
       "2                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "3                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "4                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "\n",
       "                                                                                                                       FYI  \n",
       "0  Shelley, Larry Berger has put together the 4 PAA's based on these employeef efforts on the testing of the new Flowin...  \n",
       "1  I propose that we put in place the following plan to follow-up with employees:1. Thank you from Stan to all employee...  \n",
       "2  Security, Everyone on the attached list will require after hours access to the common areas on EB39 and EB42. Please...  \n",
       "3  Please be informed, Steve Harris and the TW Commercial Group will temporarily relocated to the 13th floor effective ...  \n",
       "4  The following individuals are scheduled to move September 27th (Thursday).  Please have your boxes and equipment lab...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "from pyspark.sql.types import StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import udf, expr, substring, expr, regexp_replace, count\n",
    "\n",
    "\n",
    "udf1 = udf(to_utc_timestamp, TimestampType())\n",
    "\n",
    "temp = df.select(\n",
    "    regexp_extract(col('line'), r'Message-ID:\\s<.*>',0).alias('Message_ID'),\n",
    "    regexp_extract(col('line'), r'\\d{1,2}\\s\\w{3}\\s\\d{4}\\s\\d{2}:\\d{2}:\\d{2}\\s(\\+|\\-)\\d{4}(.*)', 0).alias(\"Date\"),\n",
    "    regexp_extract(col('line'), r'From:\\s(.*)', 0).alias(\"From\"),\n",
    "    regexp_extract(col('line'), r\"To:\\s(.+)((?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)){0,}(\\S+@\\S+)(?:\\n|\\r\\n?)Subject:\\s\", 0).alias(\"To\"),\n",
    "    regexp_extract(col('line'), r\"Subject:\\s(.+)((?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)){0,}\", 1).alias(\"Subject\"),\n",
    "    regexp_extract(col('line'), r\"Cc:\\s(.+)((?:\\n|\\r\\n?)((?:(?:\\n|\\r\\n?).+)+)){0,}(?:\\n|\\r\\n?)Mime-Version:\\s\", 0).alias(\"Cc\"),\n",
    "    regexp_extract(col('line'), r'Mime-Version:\\s(.+)', 1).alias(\"Mime_Version\"),\n",
    "    regexp_extract(col('line'), r'Content-Type:\\s(.*)', 1).alias(\"Content_Type\"),\n",
    "    regexp_extract(col('line'), r\"Content-Transfer-Encoding:\\s(.+)\", 1).alias(\"Content_Transfer_Encoding\"),\n",
    "    regexp_extract(col('line'), r\"X-From:\\s(.*)(?:\\n|\\r\\n?)X-To:\\s\", 0).alias(\"X_From\"),\n",
    "    regexp_extract(col('line'), r'X-To:\\s(.*)(?:\\n|\\r\\n?)X-cc:\\s', 0).alias(\"X_To\"),\n",
    "    regexp_extract(col('line'), r'X-cc:\\s(.*)(?:\\n|\\r\\n?)X-bcc:\\s', 0).alias(\"X_cc\"),\n",
    "    regexp_extract(col('line'), r'X-bcc:\\s(.*)(?:\\n|\\r\\n?)X-Folder:\\s', 0).alias(\"X_bcc\"),\n",
    "    regexp_extract(col('line'), r'X-Folder:\\s(.*)(?:\\n|\\r\\n?)X-Origin:\\s', 0).alias(\"X_Folder\"),\n",
    "    regexp_extract(col('line'), r\"X-Origin:\\s(.*)(?:\\n|\\r\\n?)X-FileName:\\s\", 0).alias(\"X_Origin\"),\n",
    "    regexp_extract(col('line'), r\"X-FileName:\\s(.*)\", 0).alias(\"X_FileName\"),\n",
    "    regexp_extract(col('line'), r\"X-FileName:\\s(.*)((?:\\n|\\r\\n?){1,}(.*)){1,}((?:(?:\\n|\\r\\n?).+)+)\", 0).alias(\"FYI\")\n",
    ")\n",
    "#temp.cache()\n",
    "temp1 = temp.select(\n",
    "    expr(\"substring(Message_ID, 14, length(Message_ID)-14)\").alias(\"Message_ID\"),\n",
    "    'Date', \n",
    "    udf1('Date').alias('UTC_timestamp'),\n",
    "    expr(\"substring(From, 7, length(From)-6)\").alias(\"From\"),\n",
    "    expr(\"substring(To, 5, length(To)-15)\").alias(\"To\"),\n",
    "    \"Subject\",\n",
    "    expr(\"substring(Cc, 5, length(Cc)-20)\").alias(\"Cc\"),\n",
    "    \"Mime_Version\",\n",
    "    \"Content_Type\",\n",
    "    'Content_Transfer_Encoding',\n",
    "    expr(\"substring(X_From, 9, length(X_From)-16)\").alias(\"X_From\"),\n",
    "    expr(\"substring(X_To, 7, length(X_To)-14)\").alias(\"X_To\"),\n",
    "    expr(\"substring(X_cc, 7, length(X_cc)-15)\").alias(\"X_cc\"),\n",
    "    expr(\"substring(X_bcc, 8, length(X_bcc)-19)\").alias(\"X_bcc\"),\n",
    "    expr(\"substring(X_Folder, 11, length(X_Folder)-22)\").alias(\"X_Folder\"),\n",
    "    expr(\"substring(X_Origin, 11, length(X_Origin)-24)\").alias(\"X_Origin\"),\n",
    "    expr(\"substring(X_FileName, 13, length(X_FileName)-15)\").alias(\"X_FileName\"),\n",
    "    regexp_replace(col('FYI'), r\"(X-FileName:\\s(.*)(?:\\n|\\r\\n?){1,})|(-*Original Message-*(.*)((?:\\n|\\r\\n?){1,}(.*)){0,}((?:(?:\\n|\\r\\n?).+)+))\", '').alias('FYI')\n",
    ")\n",
    "#temp1.cache()\n",
    "result = temp1.select(\n",
    "    \"Message_ID\",\n",
    "    'Date', \n",
    "    'UTC_timestamp',\n",
    "    \"From\",\n",
    "    regexp_replace(col('To'), r\"\\r\\n\\t\", \"\").alias(\"To\"),\n",
    "    \"Subject\",\n",
    "    regexp_replace(col('Cc'), r\"\\r\\n\\t\", \"\").alias(\"Cc\"),\n",
    "    \"Mime_Version\",\n",
    "    \"Content_Type\",\n",
    "    'Content_Transfer_Encoding',\n",
    "    \"X_From\",\n",
    "    \"X_To\",\n",
    "    \"X_cc\",\n",
    "    \"X_bcc\",\n",
    "    \"X_Folder\",\n",
    "    \"X_Origin\",\n",
    "    \"X_FileName\",\n",
    "    regexp_replace(col('FYI'), r\"(^\\s{1,})|(\\n{2,})\", '').alias('FYI')\n",
    ")\n",
    "\n",
    "#result.cache()\n",
    "\n",
    "result.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Display the top 10 high-frequency users based on weekly numbers of emails sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>rate_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>drew_a_brabb@calpx.com</td>\n",
       "      <td>310.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>adel.robinson@enron.com</td>\n",
       "      <td>206.522110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>34.701434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sarah.haden@enron.com</td>\n",
       "      <td>20.566066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>audrey.robertson@enron.com</td>\n",
       "      <td>20.497294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>dwagman@ftenergy.com</td>\n",
       "      <td>14.058577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>bill.rapp@enron.com</td>\n",
       "      <td>13.284716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>bob.stevens@enron.com</td>\n",
       "      <td>13.010789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>renee.perry@enron.com</td>\n",
       "      <td>10.855895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>awe@caiso.com</td>\n",
       "      <td>10.776907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         From  rate_per_week\n",
       "0      drew_a_brabb@calpx.com     310.153846\n",
       "1     adel.robinson@enron.com     206.522110\n",
       "2        lynn.blair@enron.com      34.701434\n",
       "3       sarah.haden@enron.com      20.566066\n",
       "4  audrey.robertson@enron.com      20.497294\n",
       "5        dwagman@ftenergy.com      14.058577\n",
       "6         bill.rapp@enron.com      13.284716\n",
       "7       bob.stevens@enron.com      13.010789\n",
       "8       renee.perry@enron.com      10.855895\n",
       "9               awe@caiso.com      10.776907"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, expr, substring, expr, regexp_replace, count\n",
    "from pyspark.sql.functions import unix_timestamp, col, max, min\n",
    "\n",
    "\n",
    "freq = df1.groupBy('From').agg((count('UTC_timestamp') / ( (max(unix_timestamp(col('UTC_timestamp')))-min(unix_timestamp(col('UTC_timestamp'))))/ 604800)).alias('rate_per_week')).orderBy(\"rate_per_week\",ascending=False)\n",
    "\n",
    "freq.limit(10).toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Extract top 20 keywords from the subject text for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • for the top 10 high-frequency users and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = freq.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                From|             Subject|\n",
      "+--------------------+--------------------+\n",
      "| lynn.blair@enron.co|             FW: PAA|\n",
      "|audrey.robertson@...|FW: New Location ...|\n",
      "| lynn.blair@enron.co|RE: Northern v. O...|\n",
      "| lynn.blair@enron.co|RE: Northern v. O...|\n",
      "| lynn.blair@enron.co|TW Daily Gas Cont...|\n",
      "| lynn.blair@enron.co|Re: FW: ETS Staff...|\n",
      "|sarah.haden@enron.co|EGS and Industry ...|\n",
      "| lynn.blair@enron.co|   RE: 11-01 payment|\n",
      "| lynn.blair@enron.co| FW: Agenda addition|\n",
      "| lynn.blair@enron.co|RE: Branchline Cu...|\n",
      "|renee.perry@enron.co|RE: North End Tea...|\n",
      "| lynn.blair@enron.co|FW: NNG/TW Manual...|\n",
      "| lynn.blair@enron.co|RE: Northern vs. ...|\n",
      "|sarah.haden@enron.co|EGS and Industry ...|\n",
      "|  bill.rapp@enron.co|SoCal Gas CPUC Pr...|\n",
      "|adel.robinson@enr...|Midland Revised W...|\n",
      "| lynn.blair@enron.co| RE: Reverse Auction|\n",
      "| lynn.blair@enron.co|Fw: RE: Duluth By...|\n",
      "| lynn.blair@enron.co|FW: NNG October 2...|\n",
      "| lynn.blair@enron.co|  RE: Receipt Points|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_subj = df1.join(top, df1[\"From\"] == top[\"From\"], \"inner\").select(df1['From'], df1['Subject'])\n",
    "top_subj.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CANCEL Warning Notice Stage 1 CANCELLATION Issue Warning Notice RE: North End Team Shipper/Interconnect Assignments ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  subjects\n",
       "0  CANCEL Warning Notice Stage 1 CANCELLATION Issue Warning Notice RE: North End Team Shipper/Interconnect Assignments ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws, collect_list\n",
    "\n",
    "top_texts = top_subj.groupBy(\"From\").agg(concat_ws(\" \", collect_list(\"Subject\")).alias(\"texts\"))\n",
    "top_texts = top_texts.select('texts').agg(concat_ws(\" \", collect_list(\"texts\")).alias(\"subjects\"))\n",
    "top_texts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CANCEL Warning Notice Stage 1 CANCELLATION Issue Warning Notice RE: North End Team Shipper/Interconnect Assignments ...</td>\n",
       "      <td>[cancel, warning, notice, stage, 1, cancellation, issue, warning, notice, re:, north, end, team, shipper/interconnec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  subjects  \\\n",
       "0  CANCEL Warning Notice Stage 1 CANCELLATION Issue Warning Notice RE: North End Team Shipper/Interconnect Assignments ...   \n",
       "\n",
       "                                                                                                                     words  \n",
       "0  [cancel, warning, notice, stage, 1, cancellation, issue, warning, notice, re:, north, end, team, shipper/interconnec...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer().setInputCol(\"subjects\").setOutputCol(\"words\")\n",
    "transformed = tokenizer.transform(top_texts)\n",
    "transformed.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend the stop words dictionary by adding your own stop words such as -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[cancel, warning, notice, stage, 1, cancellation, issue, warning, notice, north, end, team, shipper/interconnect, as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  filtered\n",
       "0  [cancel, warning, notice, stage, 1, cancellation, issue, warning, notice, north, end, team, shipper/interconnect, as..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + [\"-\", \"re:\", \"\", \"fw\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "\n",
    "cleaned.select('filtered').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract top 20 keywords by identifying removing the common stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)\n",
    "#featured.select('filtered','features').show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- subjects: string (nullable = false)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featured.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fw:</td>\n",
       "      <td>416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeting</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tw</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>gas</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>oneok</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>nng</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>report</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>allocation</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>storage</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>customer</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>presentation</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>northern</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>conference</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>letter</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>update</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>team</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>weekend</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>information</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>imbalance</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  counts\n",
       "0            fw:   416.0\n",
       "1        meeting   116.0\n",
       "2             tw    55.0\n",
       "3            gas    51.0\n",
       "4          oneok    45.0\n",
       "5           2001    36.0\n",
       "6            nng    35.0\n",
       "7         report    31.0\n",
       "8     allocation    30.0\n",
       "9        storage    28.0\n",
       "10      customer    27.0\n",
       "11  presentation    24.0\n",
       "12      northern    24.0\n",
       "13    conference    23.0\n",
       "14        letter    23.0\n",
       "15        update    22.0\n",
       "16          team    19.0\n",
       "17       weekend    18.0\n",
       "18   information    18.0\n",
       "19     imbalance    18.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = featured.select('features').collect()\n",
    "\n",
    "a = cvmodel.vocabulary\n",
    "b = counts[0]['features'].values\n",
    "\n",
    "d = {'words':a,'counts':b}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# • for the non-high frequency users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                From|     rate_per_week|\n",
      "+--------------------+------------------+\n",
      "|enron_update@conc...| 5.275006420289082|\n",
      "| jane.joyce@enron.co| 5.164390073122345|\n",
      "|arsystem@mailman....| 4.723819045238691|\n",
      "|kimberly.watson@e...|4.4762200808206405|\n",
      "|jeffhicken@allian...| 4.056841392124442|\n",
      "| no.address@enron.co| 4.054096867726274|\n",
      "|    register@wesc.or| 3.526352409790759|\n",
      "|   special@flowgo.co|3.5060816078083787|\n",
      "|darrell.schoolcra...| 3.484493198670269|\n",
      "|newsletter@quicki...|3.4393434852493514|\n",
      "|chairman.ken@enro...| 3.408911568204535|\n",
      "| updates@send4fun.co| 3.025528364562911|\n",
      "|intelligentxmailb...| 2.678666335967119|\n",
      "|charlie.thompson@...|2.5801057126646163|\n",
      "|john.buchanan@enr...|2.5521406572266256|\n",
      "|drew.fossum@enron.co| 2.395355039038056|\n",
      "|james.studebaker@...|2.3586809638300483|\n",
      "|jerry.graves@enro...|2.3227501238569634|\n",
      "|reyna.cabrera@enr...| 2.321687002787241|\n",
      "|randy.janzen@enro...| 2.231356685861115|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number,lit\n",
    "from pyspark.sql.window import Window\n",
    "w = Window().orderBy(lit('A'))\n",
    "bottom = freq.orderBy(\"rate_per_week\",ascending=False).withColumn(\"row_num\", row_number().over(w))\n",
    "bottom = bottom.where(col('row_num')>10).select('From','rate_per_week')\n",
    "bottom.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                From|             Subject|\n",
      "+--------------------+--------------------+\n",
      "|bradley.holmes@en...|RE: All tests wer...|\n",
      "|bradley.holmes@en...|ETS Recall NOPR C...|\n",
      "|bradley.holmes@en...|RE: A draft Busin...|\n",
      "|bradley.holmes@en...|RE: Draft - For Y...|\n",
      "|bradley.holmes@en...|Oh, the tangled w...|\n",
      "|bradley.holmes@en...|Outbound TMS Mess...|\n",
      "|bradley.holmes@en...|PAA's for Kathy a...|\n",
      "|bradley.holmes@en...|Personal Best Awa...|\n",
      "|bradley.holmes@en...|TW Negotiated Rat...|\n",
      "|bradley.holmes@en...|RE: NNG Letter as...|\n",
      "|bradley.holmes@en...|PAA's for Kathy a...|\n",
      "|bradley.holmes@en...|Personal Best Awa...|\n",
      "|bradley.holmes@en...|Business Objects ...|\n",
      "|bradley.holmes@en...|Business Objects ...|\n",
      "|bradley.holmes@en...|        Final review|\n",
      "|bradley.holmes@en...|2002 Capital IT P...|\n",
      "|bradley.holmes@en...|Customer Service ...|\n",
      "|bradley.holmes@en...|System Enhancemen...|\n",
      "|elizabeth.brown@e...|November 2001 FER...|\n",
      "|elizabeth.brown@e...|Transwestern Capa...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bottom_subj = df1.join(bottom, df1[\"From\"] == bottom[\"From\"], \"inner\").select(df1[\"From\"], df1[\"Subject\"])\n",
    "bottom_subj.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RE: All tests were not completely successfully ETS Recall NOPR Comments RE: A draft Business Continuity Plan for a S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  subjects\n",
       "0  RE: All tests were not completely successfully ETS Recall NOPR Comments RE: A draft Business Continuity Plan for a S..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws, collect_list\n",
    "\n",
    "bottom_texts = bottom_subj.groupBy(\"From\").agg(concat_ws(\" \", collect_list(\"Subject\")).alias(\"texts\"))\n",
    "bottom_texts = bottom_texts.select('texts').agg(concat_ws(\" \", collect_list(\"texts\")).alias(\"subjects\"))\n",
    "bottom_texts.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjects</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RE: All tests were not completely successfully ETS Recall NOPR Comments RE: A draft Business Continuity Plan for a S...</td>\n",
       "      <td>[re:, all, tests, were, not, completely, successfully, ets, recall, nopr, comments, re:, a, draft, business, continu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  subjects  \\\n",
       "0  RE: All tests were not completely successfully ETS Recall NOPR Comments RE: A draft Business Continuity Plan for a S...   \n",
       "\n",
       "                                                                                                                     words  \n",
       "0  [re:, all, tests, were, not, completely, successfully, ets, recall, nopr, comments, re:, a, draft, business, continu...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract word\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer().setInputCol(\"subjects\").setOutputCol(\"words\")\n",
    "transformed = tokenizer.transform(bottom_texts)\n",
    "transformed.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend the stop words dictionary by adding your own stop words such as -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[tests, completely, successfully, ets, recall, nopr, comments, draft, business, continuity, plan, short, notice, dra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  filtered\n",
       "0  [tests, completely, successfully, ets, recall, nopr, comments, draft, business, continuity, plan, short, notice, dra..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + [\"-\", \"re:\", \"fw:\", \"\", \"&\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "\n",
    "cleaned.select('filtered').toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract top 20 keywords by identifying removing the common stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mtg.</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>conference</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>room</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>eb4102</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>meeting</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>oncall</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>weekly</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>staff</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>office</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>team</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>gas</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>tms</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>tw</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>customer</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>leader</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>lynn</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>oneok</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2001</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>report</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>john</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  counts\n",
       "0         mtg.   281.0\n",
       "1   conference   274.0\n",
       "2         room   265.0\n",
       "3       eb4102   166.0\n",
       "4      meeting   144.0\n",
       "5       oncall   120.0\n",
       "6       weekly   111.0\n",
       "7        staff   107.0\n",
       "8       office    99.0\n",
       "9         team    82.0\n",
       "10         gas    73.0\n",
       "11         tms    64.0\n",
       "12          tw    58.0\n",
       "13    customer    56.0\n",
       "14      leader    54.0\n",
       "15        lynn    54.0\n",
       "16       oneok    54.0\n",
       "17        2001    52.0\n",
       "18      report    52.0\n",
       "19        john    51.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = featured.select('features').collect()\n",
    "\n",
    "a = cvmodel.vocabulary\n",
    "b = counts[0]['features'].values\n",
    "\n",
    "d = {'words':a,'counts':b}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Introduce a new column label to identify new, replied, and forwarded messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result\n",
    "\n",
    "def to_label(sbj):\n",
    "    l1 = \"RE\" if sbj.startswith(\"RE:\") else (\"FW\" if sbj.startswith(\"FW:\") else 'NEW')\n",
    "    return l1\n",
    "\n",
    "udf2 = udf(to_label, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_label = df.withColumn('label', udf2(\"Subject\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>UTC_timestamp</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Cc</th>\n",
       "      <th>Mime_Version</th>\n",
       "      <th>Content_Type</th>\n",
       "      <th>Content_Transfer_Encoding</th>\n",
       "      <th>X_From</th>\n",
       "      <th>X_To</th>\n",
       "      <th>X_cc</th>\n",
       "      <th>X_bcc</th>\n",
       "      <th>X_Folder</th>\n",
       "      <th>X_Origin</th>\n",
       "      <th>X_FileName</th>\n",
       "      <th>FYI</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>23 Aug 2001 09:24:44 -0700 (PDT)</td>\n",
       "      <td>2001-08-23 12:24:44</td>\n",
       "      <td>lynn.blair@enron.co</td>\n",
       "      <td>shelley.corman@enron.com</td>\n",
       "      <td>FW: PAA</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=LBLAIR&gt;</td>\n",
       "      <td>Corman, Shelley &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Scorman&gt;</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Outbox</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Shelley, Larry Berger has put together the 4 PAA's based on these employeef efforts on the testing of the new Flowin...</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>11 Jun 2001 14:06:00 -0700 (PDT)</td>\n",
       "      <td>2001-06-11 17:06:00</td>\n",
       "      <td>shelley.corman@enron.co</td>\n",
       "      <td>steve.hotte@enron.com, steven.january@enron.com, lynn.blair@enron.com, mike.bryant@enron.com</td>\n",
       "      <td>Follow-up on Weekend</td>\n",
       "      <td>gina.taylor@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Shelley Corman &lt;Shelley Corman/ENRON@enronXgate&gt;</td>\n",
       "      <td>Steve Hotte &lt;Steve Hotte/ENRON@enronXgate&gt;, Steven January &lt;Steven January/ET&amp;S/Enron@ENRON&gt;, Lynn Blair &lt;Lynn Blair...</td>\n",
       "      <td>Gina Taylor &lt;Gina Taylor/ENRON@enronXgate&gt;</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Tropical Storm Allison</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>I propose that we put in place the following plan to follow-up with employees:1. Thank you from Stan to all employee...</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>26 Sep 2001 06:11:50 -0700 (PDT)</td>\n",
       "      <td>2001-09-26 09:11:50</td>\n",
       "      <td>gary.kenagy@enron.co</td>\n",
       "      <td>ricki.winters@enron.com, console.security@enron.com</td>\n",
       "      <td>RE: Security Access</td>\n",
       "      <td>lynn.blair@enron.com, rick.dietz@enron.com, sheila.nacey@enron.com, bradley.holmes@enron.com, steven.january@enron.c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Kenagy, Gary &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=GKENAGY&gt;</td>\n",
       "      <td>Winters, Ricki &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rwinter&gt;, Security Console, &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Notesad...</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;, Dietz, Rick &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rdietz&gt;, Nacey, S...</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Security, Everyone on the attached list will require after hours access to the common areas on EB39 and EB42. Please...</td>\n",
       "      <td>RE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>20 Sep 2001 14:41:21 -0700 (PDT)</td>\n",
       "      <td>2001-09-20 17:41:21</td>\n",
       "      <td>audrey.robertson@enron.co</td>\n",
       "      <td>dennis.alters@enron.com, ben.asante@enron.com, ramona.betancourt@enron.com, lynn.blair@enron.com, bob.burleson@enron...</td>\n",
       "      <td>FW: New Location for Steve Harris' Staff Meeting</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Robertson, Audrey &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=AROBERT&gt;</td>\n",
       "      <td>Alters, Dennis &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dalters&gt;, Asante, Ben &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Basante&gt;, Bet...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>Please be informed, Steve Harris and the TW Commercial Group will temporarily relocated to the 13th floor effective ...</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>24 Sep 2001 14:09:13 -0700 (PDT)</td>\n",
       "      <td>2001-09-24 17:09:13</td>\n",
       "      <td>donna.scott@enron.co</td>\n",
       "      <td>darrell.schoolcraft@enron.com, terry.kowalke@enron.com, laura.giambrone@enron.com, tracy.minter@enron.com, amy.mulli...</td>\n",
       "      <td>TW Move Information</td>\n",
       "      <td>lynn.blair@enron.com, steven.january@enron.com, john.buchanan@enron.com, donna.scott@enron.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Scott, Donna &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=DSCOTT1&gt;</td>\n",
       "      <td>Schoolcraft, Darrell &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dschool&gt;, Kowalke, Terry &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tkow...</td>\n",
       "      <td>Blair, Lynn &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair&gt;, January, Steven &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=Sjanuary&gt;, Bu...</td>\n",
       "      <td></td>\n",
       "      <td>\\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move</td>\n",
       "      <td>Blair-L</td>\n",
       "      <td>LBLAIR (Non-Privileged).</td>\n",
       "      <td>The following individuals are scheduled to move September 27th (Thursday).  Please have your boxes and equipment lab...</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID                              Date       UTC_timestamp                       From  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme  23 Aug 2001 09:24:44 -0700 (PDT) 2001-08-23 12:24:44        lynn.blair@enron.co   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme  11 Jun 2001 14:06:00 -0700 (PDT) 2001-06-11 17:06:00    shelley.corman@enron.co   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme  26 Sep 2001 06:11:50 -0700 (PDT) 2001-09-26 09:11:50       gary.kenagy@enron.co   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme  20 Sep 2001 14:41:21 -0700 (PDT) 2001-09-20 17:41:21  audrey.robertson@enron.co   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme  24 Sep 2001 14:09:13 -0700 (PDT) 2001-09-24 17:09:13       donna.scott@enron.co   \n",
       "\n",
       "                                                                                                                        To  \\\n",
       "0                                                                                                 shelley.corman@enron.com   \n",
       "1                             steve.hotte@enron.com, steven.january@enron.com, lynn.blair@enron.com, mike.bryant@enron.com   \n",
       "2                                                                      ricki.winters@enron.com, console.security@enron.com   \n",
       "3  dennis.alters@enron.com, ben.asante@enron.com, ramona.betancourt@enron.com, lynn.blair@enron.com, bob.burleson@enron...   \n",
       "4  darrell.schoolcraft@enron.com, terry.kowalke@enron.com, laura.giambrone@enron.com, tracy.minter@enron.com, amy.mulli...   \n",
       "\n",
       "                                            Subject  \\\n",
       "0                                           FW: PAA   \n",
       "1                              Follow-up on Weekend   \n",
       "2                               RE: Security Access   \n",
       "3  FW: New Location for Steve Harris' Staff Meeting   \n",
       "4                               TW Move Information   \n",
       "\n",
       "                                                                                                                        Cc Mime_Version  \\\n",
       "0                                                                                                     lynn.blair@enron.com          1.0   \n",
       "1                                                                                                    gina.taylor@enron.com          1.0   \n",
       "2  lynn.blair@enron.com, rick.dietz@enron.com, sheila.nacey@enron.com, bradley.holmes@enron.com, steven.january@enron.c...          1.0   \n",
       "3                                                                                                                                   1.0   \n",
       "4                           lynn.blair@enron.com, steven.january@enron.com, john.buchanan@enron.com, donna.scott@enron.com          1.0   \n",
       "\n",
       "                   Content_Type Content_Transfer_Encoding                                                       X_From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit         Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=LBLAIR>   \n",
       "1  text/plain; charset=us-ascii                      7bit             Shelley Corman <Shelley Corman/ENRON@enronXgate>   \n",
       "2  text/plain; charset=us-ascii                      7bit       Kenagy, Gary </O=ENRON/OU=NA/CN=RECIPIENTS/CN=GKENAGY>   \n",
       "3  text/plain; charset=us-ascii                      7bit  Robertson, Audrey </O=ENRON/OU=NA/CN=RECIPIENTS/CN=AROBERT>   \n",
       "4  text/plain; charset=us-ascii                      7bit       Scott, Donna </O=ENRON/OU=NA/CN=RECIPIENTS/CN=DSCOTT1>   \n",
       "\n",
       "                                                                                                                      X_To  \\\n",
       "0                                                                Corman, Shelley </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Scorman>   \n",
       "1  Steve Hotte <Steve Hotte/ENRON@enronXgate>, Steven January <Steven January/ET&S/Enron@ENRON>, Lynn Blair <Lynn Blair...   \n",
       "2  Winters, Ricki </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rwinter>, Security Console, </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Notesad...   \n",
       "3  Alters, Dennis </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dalters>, Asante, Ben </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Basante>, Bet...   \n",
       "4  Schoolcraft, Darrell </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Dschool>, Kowalke, Terry </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Tkow...   \n",
       "\n",
       "                                                                                                                      X_cc X_bcc  \\\n",
       "0                                                                     Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>         \n",
       "1                                                                               Gina Taylor <Gina Taylor/ENRON@enronXgate>         \n",
       "2  Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>, Dietz, Rick </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Rdietz>, Nacey, S...         \n",
       "3                                                                                                                                  \n",
       "4  Blair, Lynn </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Lblair>, January, Steven </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Sjanuary>, Bu...         \n",
       "\n",
       "                                                      X_Folder X_Origin                X_FileName  \\\n",
       "0                  \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Outbox  Blair-L  LBLAIR (Non-Privileged).   \n",
       "1  \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Tropical Storm Allison  Blair-L  LBLAIR (Non-Privileged).   \n",
       "2                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "3                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "4                    \\LBLAIR (Non-Privileged)\\Blair, Lynn\\Move  Blair-L  LBLAIR (Non-Privileged).   \n",
       "\n",
       "                                                                                                                       FYI label  \n",
       "0  Shelley, Larry Berger has put together the 4 PAA's based on these employeef efforts on the testing of the new Flowin...    FW  \n",
       "1  I propose that we put in place the following plan to follow-up with employees:1. Thank you from Stan to all employee...   NEW  \n",
       "2  Security, Everyone on the attached list will require after hours access to the common areas on EB39 and EB42. Please...    RE  \n",
       "3  Please be informed, Steve Harris and the TW Commercial Group will temporarily relocated to the 13th floor effective ...    FW  \n",
       "4  The following individuals are scheduled to move September 27th (Thursday).  Please have your boxes and equipment lab...   NEW  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_label.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Get the trend of the over mail activity using the pivot table from spark itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>FW</th>\n",
       "      <th>NEW</th>\n",
       "      <th>RE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1259</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>337</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>278</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>86</td>\n",
       "      <td>202</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month   FW   NEW   RE\n",
       "0   2000      1    0     2    0\n",
       "1   2000      5    0     3    0\n",
       "2   2000      6    0     9    0\n",
       "3   2000      7    1    14    0\n",
       "4   2000      8    0    41    0\n",
       "5   2001      5    1    21    3\n",
       "6   2001      6   21  1259   18\n",
       "7   2001      7   74    50   40\n",
       "8   2001      8   54    36   40\n",
       "9   2001      9   91    84   87\n",
       "10  2001     10  115   337  172\n",
       "11  2001     11   87   278   99\n",
       "12  2001     12   86   202  114\n",
       "13  2002      1    0     6    0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, year, month\n",
    "\n",
    "pivotDF = df_with_label.groupBy(year(\"UTC_timestamp\").alias('year'), month(\"UTC_timestamp\").alias('month')).pivot(\"label\").count().orderBy(\"year\", \"month\")\n",
    "\n",
    "\n",
    "pivotDF.na.fill(0).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Use k-means clustering to create 4 clusters from the extracted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = result.select(\"Message_ID\",\"From\", \"Subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract words from the body of email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>From</th>\n",
       "      <th>Subject</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>lynn.blair@enron.co</td>\n",
       "      <td>FW: PAA</td>\n",
       "      <td>[fw:, paa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Message_ID                 From  Subject       words\n",
       "0  9838605.1075853079790.JavaMail.evans@thyme  lynn.blair@enron.co  FW: PAA  [fw:, paa]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw = result.select(\"Message_ID\",\"FYI\")\n",
    "\n",
    "# Extract word\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer().setInputCol(\"Subject\").setOutputCol(\"words\")\n",
    "transformed = tokenizer.transform(raw)\n",
    "transformed.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>[fw:, paa]</td>\n",
       "      <td>[paa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>[follow-up, on, weekend]</td>\n",
       "      <td>[follow-up, weekend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>[re:, security, access]</td>\n",
       "      <td>[security, access]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>[fw:, new, location, for, steve, harris', staff, meeting]</td>\n",
       "      <td>[new, location, steve, harris', staff, meeting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>[tw, move, information]</td>\n",
       "      <td>[tw, move, information]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>25384781.1075853023617.JavaMail.evans@thyme</td>\n",
       "      <td>[your, may, 31, pay, advice]</td>\n",
       "      <td>[may, 31, pay, advice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28564115.1075861911305.JavaMail.evans@thyme</td>\n",
       "      <td>[nng, card, list, by, team]</td>\n",
       "      <td>[nng, card, list, team]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6940252.1075861911480.JavaMail.evans@thyme</td>\n",
       "      <td>[fw:, tw, negotiated, rates, , (message, from, greg, porter)]</td>\n",
       "      <td>[tw, negotiated, rates, (message, greg, porter)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17994977.1075853083873.JavaMail.evans@thyme</td>\n",
       "      <td>[re:, tw, index, deals]</td>\n",
       "      <td>[tw, index, deals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15493730.1075853083897.JavaMail.evans@thyme</td>\n",
       "      <td>[re:, tw, index, deals]</td>\n",
       "      <td>[tw, index, deals]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID                                                          words  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme                                                     [fw:, paa]   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme                                       [follow-up, on, weekend]   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme                                        [re:, security, access]   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme      [fw:, new, location, for, steve, harris', staff, meeting]   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme                                        [tw, move, information]   \n",
       "5  25384781.1075853023617.JavaMail.evans@thyme                                   [your, may, 31, pay, advice]   \n",
       "6  28564115.1075861911305.JavaMail.evans@thyme                                    [nng, card, list, by, team]   \n",
       "7   6940252.1075861911480.JavaMail.evans@thyme  [fw:, tw, negotiated, rates, , (message, from, greg, porter)]   \n",
       "8  17994977.1075853083873.JavaMail.evans@thyme                                        [re:, tw, index, deals]   \n",
       "9  15493730.1075853083897.JavaMail.evans@thyme                                        [re:, tw, index, deals]   \n",
       "\n",
       "                                           filtered  \n",
       "0                                             [paa]  \n",
       "1                              [follow-up, weekend]  \n",
       "2                                [security, access]  \n",
       "3   [new, location, steve, harris', staff, meeting]  \n",
       "4                           [tw, move, information]  \n",
       "5                            [may, 31, pay, advice]  \n",
       "6                           [nng, card, list, team]  \n",
       "7  [tw, negotiated, rates, (message, greg, porter)]  \n",
       "8                                [tw, index, deals]  \n",
       "9                                [tw, index, deals]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "# custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + [\"-\", \"re:\", \"fw:\", \"\", \"&\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "cleaned = cleaned.select(\"Message_ID\",\"words\", \"filtered\")\n",
    "cleaned.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the features from e-mail subjects using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=4, seed=1)  # 4 clusters here\n",
    "model = kmeans.fit(featured.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>[fw:, paa]</td>\n",
       "      <td>[paa]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>[follow-up, on, weekend]</td>\n",
       "      <td>[follow-up, weekend]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>[re:, security, access]</td>\n",
       "      <td>[security, access]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>[fw:, new, location, for, steve, harris', staff, meeting]</td>\n",
       "      <td>[new, location, steve, harris', staff, meeting]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>[tw, move, information]</td>\n",
       "      <td>[tw, move, information]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID                                                      words  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme                                                 [fw:, paa]   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme                                   [follow-up, on, weekend]   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme                                    [re:, security, access]   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme  [fw:, new, location, for, steve, harris', staff, meeting]   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme                                    [tw, move, information]   \n",
       "\n",
       "                                          filtered  \\\n",
       "0                                            [paa]   \n",
       "1                             [follow-up, weekend]   \n",
       "2                               [security, access]   \n",
       "3  [new, location, steve, harris', staff, meeting]   \n",
       "4                          [tw, move, information]   \n",
       "\n",
       "                                                                                                                  features  prediction  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0  \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0  \n",
       "3  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...           1  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = model.transform(featured)\n",
    "transformed.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0| 2895|\n",
      "|         1|  258|\n",
      "|         2|  247|\n",
      "|         3|   45|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.groupBy(\"prediction\").count().orderBy(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Use LDA to generate 4 topics from the extracted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def get_topic(cluster):\n",
    "    #list_of_list_of_tokens\n",
    "    list_of_list_of_tokens  = [row.filtered for row in transformed.filter(col(\"prediction\")==cluster).select(\"filtered\").collect()]\n",
    "\n",
    "\n",
    "    dictionary_LDA = corpora.Dictionary(list_of_list_of_tokens)\n",
    "    #dictionary_LDA.filter_extremes(no_below=3)\n",
    "    corpus = [dictionary_LDA.doc2bow(list_of_tokens) for list_of_tokens in list_of_list_of_tokens]\n",
    "\n",
    "    num_topics = 1\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                      id2word=dictionary_LDA, \\\n",
    "                                      passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                      eta=[0.01]*len(dictionary_LDA.keys()))\n",
    "    string = \"\"\n",
    "    for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=6):\n",
    "        string += (str(i)+\": \"+ topic)\n",
    "        string += (\"\\n\")\n",
    "    \n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.034*\"oncall\" + 0.025*\"office\" + 0.015*\"lynn\" + 0.015*\"john\" + 0.014*\"mtg.\" + 0.013*\"terry\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_topic(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.240*\"meeting\" + 0.031*\"staff\" + 0.023*\"tw\" + 0.018*\"winter\" + 0.016*\"gas\" + 0.016*\"room\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_topic(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.159*\"conference\" + 0.158*\"room\" + 0.150*\"mtg.\" + 0.102*\"eb4102\" + 0.036*\"staff\" + 0.032*\"weekly\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_topic(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.326*\"mtg./raetta\" + 0.326*\"priority\" + 0.326*\"weekly\" + 0.007*\"delete\" + 0.007*\"parent\" + 0.007*\"repeat\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_topic(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = result.select(\"Message_ID\",\"From\", \"FYI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_clean_str(x):\n",
    "    punc='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    lowercased_str = x.lower()\n",
    "    for ch in punc:\n",
    "        lowercased_str = lowercased_str.replace(ch, '')\n",
    "    return lowercased_str\n",
    "\n",
    "udf3 = udf (lower_clean_str, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.select(\"Message_ID\",\"From\", udf3(\"FYI\").alias('FYI'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>From</th>\n",
       "      <th>FYI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>shelley larry berger has put together the 4 paas based on these employeef efforts on the testing of the new flowing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>shelley.corman@enron.com</td>\n",
       "      <td>i propose that we put in place the following plan to followup with employees1 thank you from stan to all employees t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>gary.kenagy@enron.com</td>\n",
       "      <td>security everyone on the attached list will require after hours access to the common areas on eb39 and eb42 please c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>audrey.robertson@enron.com</td>\n",
       "      <td>please be informed steve harris and the tw commercial group will temporarily relocated to the 13th floor effective m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>donna.scott@enron.com</td>\n",
       "      <td>the following individuals are scheduled to move september 27th thursday  please have your boxes and equipment labele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID                        From  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme        lynn.blair@enron.com   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme    shelley.corman@enron.com   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme       gary.kenagy@enron.com   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme  audrey.robertson@enron.com   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme       donna.scott@enron.com   \n",
       "\n",
       "                                                                                                                       FYI  \n",
       "0  shelley larry berger has put together the 4 paas based on these employeef efforts on the testing of the new flowing ...  \n",
       "1  i propose that we put in place the following plan to followup with employees1 thank you from stan to all employees t...  \n",
       "2  security everyone on the attached list will require after hours access to the common areas on eb39 and eb42 please c...  \n",
       "3  please be informed steve harris and the tw commercial group will temporarily relocated to the 13th floor effective m...  \n",
       "4  the following individuals are scheduled to move september 27th thursday  please have your boxes and equipment labele...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>From</th>\n",
       "      <th>FYI</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>shelley larry berger has put together the 4 paas based on these employeef efforts on the testing of the new flowing ...</td>\n",
       "      <td>[shelley, larry, berger, has, put, together, the, 4, paas, based, on, these, employeef, efforts, on, the, testing, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Message_ID                  From  \\\n",
       "0  9838605.1075853079790.JavaMail.evans@thyme  lynn.blair@enron.com   \n",
       "\n",
       "                                                                                                                       FYI  \\\n",
       "0  shelley larry berger has put together the 4 paas based on these employeef efforts on the testing of the new flowing ...   \n",
       "\n",
       "                                                                                                                     words  \n",
       "0  [shelley, larry, berger, has, put, together, the, 4, paas, based, on, these, employeef, efforts, on, the, testing, o...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw = result.select(\"Message_ID\",\"FYI\")\n",
    "\n",
    "# Extract word\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer().setInputCol(\"FYI\").setOutputCol(\"words\")\n",
    "transformed = tokenizer.transform(raw)\n",
    "transformed.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message_ID</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9838605.1075853079790.JavaMail.evans@thyme</td>\n",
       "      <td>[shelley, larry, berger, has, put, together, the, 4, paas, based, on, these, employeef, efforts, on, the, testing, o...</td>\n",
       "      <td>[shelley, larry, berger, put, together, 4, paas, based, employeef, efforts, testing, new, flowing, gas, documents, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14271690.1075853083553.JavaMail.evans@thyme</td>\n",
       "      <td>[i, propose, that, we, put, in, place, the, following, plan, to, followup, with, employees1, thank, you, from, stan,...</td>\n",
       "      <td>[propose, put, place, following, plan, followup, employees1, thank, stan, employees, worked, emergency, plan, weeken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18165833.1075853083239.JavaMail.evans@thyme</td>\n",
       "      <td>[security, everyone, on, the, attached, list, will, require, after, hours, access, to, the, common, areas, on, eb39,...</td>\n",
       "      <td>[security, everyone, attached, list, require, hours, access, common, areas, eb39, eb42, please, configure, access, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982727.1075853083190.JavaMail.evans@thyme</td>\n",
       "      <td>[please, be, informed, steve, harris, and, the, tw, commercial, group, will, temporarily, relocated, to, the, 13th, ...</td>\n",
       "      <td>[please, informed, steve, harris, tw, commercial, group, temporarily, relocated, 13th, floor, effective, monday, sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22618928.1075853083215.JavaMail.evans@thyme</td>\n",
       "      <td>[the, following, individuals, are, scheduled, to, move, september, 27th, thursday, , please, have, your, boxes, and,...</td>\n",
       "      <td>[following, individuals, scheduled, move, september, 27th, thursday, please, boxes, equipment, labeled, 530, pm, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>25384781.1075853023617.JavaMail.evans@thyme</td>\n",
       "      <td>[this, message, is, to, inform, you, that, information, contained, on, your, printed, pay, advice, for, the, pay, pe...</td>\n",
       "      <td>[message, inform, information, contained, printed, pay, advice, pay, period, ending, may, 31, 2001, may, misleadingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28564115.1075861911305.JavaMail.evans@thyme</td>\n",
       "      <td>[see, the, attached, for, the, nng, card, list, by, team, sc, southcentral, team, nnorth, team, and, scn, means, bot...</td>\n",
       "      <td>[see, attached, nng, card, list, team, sc, southcentral, team, nnorth, team, scn, means, claim, customer, john, buch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6940252.1075861911480.JavaMail.evans@thyme</td>\n",
       "      <td>[per, our, conversation, at, staff, meeting, today, , please, see, discussion, of, lookup, capacity, below]</td>\n",
       "      <td>[per, conversation, staff, meeting, today, please, see, discussion, lookup, capacity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17994977.1075853083873.JavaMail.evans@thyme</td>\n",
       "      <td>[alllooking, back, through, my, postings, for, tw, there, was, only, one, posting, in, the, two, month, period, in, ...</td>\n",
       "      <td>[alllooking, back, postings, tw, one, posting, two, month, period, question, pertained, available, capacity, open, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15493730.1075853083897.JavaMail.evans@thyme</td>\n",
       "      <td>[i, found, one, note, dated, 12800, asking, toby, kuehl, to, post, jan, 2001, lft, capacity, for, one, day, , , this...</td>\n",
       "      <td>[found, one, note, dated, 12800, asking, toby, kuehl, post, jan, 2001, lft, capacity, one, day, capacity, sold, semp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Message_ID  \\\n",
       "0   9838605.1075853079790.JavaMail.evans@thyme   \n",
       "1  14271690.1075853083553.JavaMail.evans@thyme   \n",
       "2  18165833.1075853083239.JavaMail.evans@thyme   \n",
       "3   5982727.1075853083190.JavaMail.evans@thyme   \n",
       "4  22618928.1075853083215.JavaMail.evans@thyme   \n",
       "5  25384781.1075853023617.JavaMail.evans@thyme   \n",
       "6  28564115.1075861911305.JavaMail.evans@thyme   \n",
       "7   6940252.1075861911480.JavaMail.evans@thyme   \n",
       "8  17994977.1075853083873.JavaMail.evans@thyme   \n",
       "9  15493730.1075853083897.JavaMail.evans@thyme   \n",
       "\n",
       "                                                                                                                     words  \\\n",
       "0  [shelley, larry, berger, has, put, together, the, 4, paas, based, on, these, employeef, efforts, on, the, testing, o...   \n",
       "1  [i, propose, that, we, put, in, place, the, following, plan, to, followup, with, employees1, thank, you, from, stan,...   \n",
       "2  [security, everyone, on, the, attached, list, will, require, after, hours, access, to, the, common, areas, on, eb39,...   \n",
       "3  [please, be, informed, steve, harris, and, the, tw, commercial, group, will, temporarily, relocated, to, the, 13th, ...   \n",
       "4  [the, following, individuals, are, scheduled, to, move, september, 27th, thursday, , please, have, your, boxes, and,...   \n",
       "5  [this, message, is, to, inform, you, that, information, contained, on, your, printed, pay, advice, for, the, pay, pe...   \n",
       "6  [see, the, attached, for, the, nng, card, list, by, team, sc, southcentral, team, nnorth, team, and, scn, means, bot...   \n",
       "7              [per, our, conversation, at, staff, meeting, today, , please, see, discussion, of, lookup, capacity, below]   \n",
       "8  [alllooking, back, through, my, postings, for, tw, there, was, only, one, posting, in, the, two, month, period, in, ...   \n",
       "9  [i, found, one, note, dated, 12800, asking, toby, kuehl, to, post, jan, 2001, lft, capacity, for, one, day, , , this...   \n",
       "\n",
       "                                                                                                                  filtered  \n",
       "0  [shelley, larry, berger, put, together, 4, paas, based, employeef, efforts, testing, new, flowing, gas, documents, g...  \n",
       "1  [propose, put, place, following, plan, followup, employees1, thank, stan, employees, worked, emergency, plan, weeken...  \n",
       "2  [security, everyone, attached, list, require, hours, access, common, areas, eb39, eb42, please, configure, access, f...  \n",
       "3  [please, informed, steve, harris, tw, commercial, group, temporarily, relocated, 13th, floor, effective, monday, sep...  \n",
       "4  [following, individuals, scheduled, move, september, 27th, thursday, please, boxes, equipment, labeled, 530, pm, rec...  \n",
       "5  [message, inform, information, contained, printed, pay, advice, pay, period, ending, may, 31, 2001, may, misleadingr...  \n",
       "6  [see, attached, nng, card, list, team, sc, southcentral, team, nnorth, team, scn, means, claim, customer, john, buch...  \n",
       "7                                    [per, conversation, staff, meeting, today, please, see, discussion, lookup, capacity]  \n",
       "8  [alllooking, back, postings, tw, one, posting, two, month, period, question, pertained, available, capacity, open, s...  \n",
       "9  [found, one, note, dated, 12800, asking, toby, kuehl, post, jan, 2001, lft, capacity, one, day, capacity, sold, semp...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "# custom stopwords\n",
    "stopwords = StopWordsRemover().getStopWords() + [\"-\", \"re:\", \"fw:\", \"\", \"&\"]\n",
    "remover = StopWordsRemover().setStopWords(stopwords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "cleaned = cleaned.select(\"Message_ID\",\"words\", \"filtered\")\n",
    "cleaned.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2261a446a660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizerModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filtered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beam/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "cvmodel = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(cleaned)\n",
    "featured = cvmodel.transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=4, seed=1)  # 4 clusters here\n",
    "model = kmeans.fit(featured.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
